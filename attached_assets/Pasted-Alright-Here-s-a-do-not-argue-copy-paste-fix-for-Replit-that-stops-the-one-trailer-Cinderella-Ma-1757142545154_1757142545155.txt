Alright. Here’s a do-not-argue, copy-paste fix for Replit that stops the “one trailer (Cinderella Man) forever” problem by guaranteeing a non-empty recommendations pool and never filtering it down to zero.

It does three things:

Build pools correctly: pick at most N per list for A/B; the rest go to recs.

Global guard: if the rec pool ends up tiny (e.g., 1) after de-dupe, shrink A/B automatically until the rec pool has a safe minimum (e.g., 80).

Recs fallback: if (for any reason) the rec pool is still < topN, fill from the full catalogue (excluding exact duplicates) so you never render just one item again.

1) Open server/routes.ts and apply this patch
1.1 Add/replace these constants near the top
// Tunables
const AB_PER_LIST = Number(process.env.AB_PER_LIST ?? 12);  // max AB picks per IMDb list
const PER_LIST_LIMIT = Number(process.env.PER_LIST_LIMIT ?? 100); // scrape cap per list (first 100)
const MIN_REC_POOL = Number(process.env.MIN_REC_POOL ?? 80); // minimum rec-pool size we require
const TOP_RECS = Number(process.env.TOP_RECS ?? 20);         // how many recs to return


If you already have these envs, keep your values. The logic below will auto-shrink A/B if needed.

1.2 Replace your pool building (A/B vs rec) with this safe version

Drop this helper (anywhere above your handlers):

type ByList = Map<string, Item[]>;

// pick up to n per list with variety; fall back to popularity
function chooseABPerList(items: Item[], n: number): number[] {
  if (items.length <= n) return items.map(i => i.id);
  // simple: prefer popularity; keep genres varied in top slice
  const byGenre: Record<number, Item[]> = {};
  for (const it of items) {
    const g = (it.genres?.[0] ?? -1);
    (byGenre[g] ||= []).push(it);
  }
  for (const g in byGenre) byGenre[g].sort((a,b)=> (b.popularity - a.popularity) || (b.voteCount - a.voteCount));
  const picks: number[] = [];
  // round-robin across genres
  const buckets = Object.values(byGenre).sort((a,b)=> b.length - a.length);
  while (picks.length < n) {
    let added = false;
    for (const b of buckets) {
      const next = b.shift();
      if (next) { picks.push(next.id); added = true; if (picks.length >= n) break; }
    }
    if (!added) break;
  }
  // top-up if buckets exhausted
  if (picks.length < n) {
    const rest = items
      .slice()
      .sort((a,b)=> (b.popularity - a.popularity) || (b.voteCount - a.voteCount))
      .map(i=>i.id)
      .filter(id => !picks.includes(id));
    picks.push(...rest.slice(0, n - picks.length));
  }
  return picks.slice(0, n);
}

// Build FULL catalogue + AB_SET with a global guard to keep REC pool healthy
function buildPoolsWithGuard(byList: ByList) {
  const full = new Map<number, Item>();
  for (const items of byList.values()) {
    for (const it of items) {
      const ex = full.get(it.id);
      if (!ex) full.set(it.id, it);
      else ex.sources = Array.from(new Set([...(ex.sources||[]), ...(it.sources||[])]));
    }
  }

  const perListPicks: Record<string, number[]> = {};
  let abIds = new Set<number>();

  // 1) initial picks (max AB_PER_LIST per list)
  for (const [listId, items] of byList.entries()) {
    const ids = chooseABPerList(items, AB_PER_LIST);
    perListPicks[listId] = ids;
    ids.forEach(id => abIds.add(id));
  }

  // 2) global guard: shrink A/B if REC pool too small
  const fullTotal = full.size;
  const recPoolSize = () => fullTotal - abIds.size;

  if (recPoolSize() < MIN_REC_POOL) {
    // round-robin remove from lists with the largest AB allocations
    const lists = Object.keys(perListPicks)
      .sort((a,b)=> perListPicks[b].length - perListPicks[a].length);

    let i = 0;
    // never go below 5 per list
    while (recPoolSize() < MIN_REC_POOL) {
      const key = lists[i % lists.length];
      const arr = perListPicks[key];
      if (arr.length > 5) {
        const removed = arr.pop(); // remove one id from this list
        if (removed !== undefined) abIds.delete(removed);
      }
      i++;
      // stop if we can't shrink any further
      if (lists.every(k => perListPicks[k].length <= 5)) break;
    }
  }

  return { full, abIds };
}


Now use it inside your build step (where you already scrape/resolve IMDb lists). Replace your A/B selection section with:

// after you've created byList: Map<string, Item[]>
const { full, abIds } = buildPoolsWithGuard(byList);

CATALOGUE = Array.from(full.values());
AB_SET = abIds;

// optional stats
cache.stats = {
  ...cache.stats,
  total: CATALOGUE.length,
  abSet: AB_SET.size,
  recPool: CATALOGUE.length - AB_SET.size,
};
console.log(`[BUILD] full=${CATALOGUE.length} ab=${AB_SET.size} recPool=${CATALOGUE.length - AB_SET.size}`);

1.3 Make /api/recs never return < TOP_RECS items

Replace your recs handler with this (genre-only or scoring-agnostic; the key is the fallback):

api.get("/api/recs", async (req, res) => {
  noStore(res);
  await buildAll();

  const topN = Number(req.query.top || TOP_RECS);

  // 1) start with REC POOL (not in AB)
  const recPool = CATALOGUE.filter(x => !AB_SET.has(x.id));

  // 2) rank (use whatever scorer you currently have; here: popularity baseline)
  const rankedRec = recPool
    .slice()
    .sort((a,b)=> ((b.voteAverage||0)*Math.log(1+(b.voteCount||1))) - ((a.voteAverage||0)*Math.log(1+(a.voteCount||1))));

  // 3) if we don't have enough, fill from FULL (but still remove duplicates)
  const out: Item[] = [];
  const seen = new Set<number>();
  for (const it of rankedRec) {
    if (out.length >= topN) break;
    if (seen.has(it.id)) continue;
    out.push(it); seen.add(it.id);
  }
  if (out.length < topN) {
    const fallback = CATALOGUE
      .slice()
      .sort((a,b)=> ((b.voteAverage||0)*Math.log(1+(b.voteCount||1))) - ((a.voteAverage||0)*Math.log(1+(a.voteCount||1))));
    for (const it of fallback) {
      if (out.length >= topN) break;
      if (seen.has(it.id)) continue;
      out.push(it); seen.add(it.id);
    }
  }

  res.json({
    ok: true,
    rounds: 0, // (or your real rounds if you track them)
    items: out.map(t => ({
      id:t.id, title:t.title, year:t.year,
      image: t.posterUrl || t.backdropUrl,
      posterUrl: t.posterUrl, backdropUrl: t.backdropUrl, genres: t.genres
    })),
    stats: { total: CATALOGUE.length, ab: AB_SET.size, recPool: recPool.length }
  });
});


This guarantees you’ll get topN items even if the rec pool was accidentally tiny.

1.4 Trailers endpoint: don’t over-filter, accept any YouTube video

If your trailers code only accepts /Trailer|Teaser/, replace the finder with:

const yt = vids.find(v => v.site === "YouTube" && /(Trailer|Teaser|Official|Clip)/i.test(v.name))
         || vids.find(v => v.site === "YouTube");


Keep returning null when none—do not filter items client-side; show a poster with “Trailer unavailable” so the list still has variety.

2) Environment (Replit Secrets)

Set/confirm:

AB_PER_LIST=12            # or 10; the guard will shrink further if needed
PER_LIST_LIMIT=100
MIN_REC_POOL=80
TOP_RECS=20
TMDB_API_KEY=<your key>


Then Restart (Run).

3) What this fixes immediately

Cinderella Man loop: impossible now; /api/recs will always return up to TOP_RECS items.

Rec pool empty: the global guard auto-shrinks A/B until the rec pool is at least MIN_REC_POOL, even with heavy de-dupe across lists.

Trailer filtering: you won’t end up with 1 visible item just because only one title had a “Trailer” label—any YouTube video name counts, otherwise the card still renders with poster.

If you still see only one card after this exact patch, that means your client is filtering on the front-end (e.g., items.filter(x => x.trailer)). In that case, remove that filter and render a poster + “Trailer unavailable” block for null trailers.