the recomendations and testing isnt quite working can you look at this do some research put your coding and film buff hats on and come up with a good way to make this work. We are close but its just off. https://www.google.com/search?q=whats+the+best+way+to+figure+out+what+movie+to+watch&oq=whats+the+best+way+to+figure+out+what+movie+to+watch&gs_lcrp=EgZjaHJvbWUyCwgAEEUYChg5GKABMgkIARAhGAoYoAHSAQkxMjE4M2owajeoAgCwAgA&sourceid=chrome&ie=UTF-8
ChatGPT said:
Thought for 1m 15s

You’re right—you’re close, but the chooser + recommender need two things Netflix-style systems use all the time: learn from pairwise choices properly and pick the next pair that’s maximally informative, then re-rank final trailers for diversity (not 5 near-duplicates). Here’s a tight plan + drop-in code to make it click.

Why this approach?

Netflix leans on bandits for interactive personalization and exploration (contextual bandits) rather than static A/B only. 
reforge.com
geteppo.com
Scale Events

Your 12 A/B taps are perfect for a pairwise model like Bradley-Terry/Luce (learn preferences from head-to-head wins). 
Stanford University
ACER
Dueling Bandit Toolkit

Final 5 should be relevant + non-redundant using a simple diversity re-ranker like MMR. 
CMU School of Computer Science
ANU CECS Users

What we’ll change (summary)

Learn tastes with pairwise updates (BTL-ish).
Each A/B win updates a weight vector over features (genres, decade, runtime/pace, popularity). This is stronger than “cosine of raw vectors.”

Ask smarter next questions.
Pick the next pair where your model is most uncertain (predicted ~50/50) and the two films are far apart in features (max information gain). This gives crisp signals in 12 rounds.

Final 5 trailers: score by your learned vector, then apply MMR (Maximal Marginal Relevance) + brand/source caps so the 5 feel personal and varied.

You keep the one-trailer UI. The A/B pool can still be your famous “anchor” set; the final trailers still come from the full catalogue with working YouTube embeds + where-to-watch.

Drop-in code (TypeScript/React) — keep your file names, paste where noted
1) Learn from pairwise choices (client/src/lib/taste.ts)
// Lightweight online pairwise learner (BTL-ish logistic update).
// w is your taste weights; phi(movie) is your feature vector.
// Call updateBTL(w, winner, loser) after each A/B choice.

export type Vec = number[];

export function dot(a: Vec, b: Vec) {
  let s = 0, n = Math.min(a.length, b.length);
  for (let i = 0; i < n; i++) s += a[i]*b[i];
  return s;
}
export function addInPlace(a: Vec, b: Vec, scale = 1) {
  for (let i = 0; i < Math.min(a.length,b.length); i++) a[i] += scale*b[i];
}
export function norm(a: Vec) {
  const l = Math.sqrt(a.reduce((s,x)=>s+x*x,0)) || 1;
  return a.map(x=>x/l);
}

// Online BTL-style update: p = σ(w·(φwin - φlose)); w += η * (1 - p) * (φwin - φlose) - λ w
export function updateBTL(w: Vec, phiWin: Vec, phiLose: Vec, eta = 0.6, l2 = 0.01) {
  const diff = phiWin.map((x,i)=> x - (phiLose[i] || 0));
  const m = dot(w, diff);
  const p = 1/(1+Math.exp(-m));            // predicted prob winner>loser
  const grad = (1 - p);                     // logistic gradient
  // regularize a bit
  for (let i = 0; i < w.length; i++) w[i] = (1 - l2) * w[i];
  addInPlace(w, diff, eta * grad);
  // keep vector stable
  const n = Math.sqrt(w.reduce((s,x)=>s+x*x,0));
  if (n > 0) for (let i=0;i<w.length;i++) w[i] /= n;
  return w;
}

2) Feature vector (client/src/lib/phi.ts)

Use things you already have (genres, year/decade, runtime, popularity). This is enough.

import type { Title } from "../hooks/useEnhancedCatalogue";

// Build a ~40–60D vector: genres (one-hot), decade, pace, mainstreamness.
export function phi(t: Title, genreSpace: number[] = []): number[] {
  const gset = new Set(t.genres || []);
  const G = Math.max(19, Math.max(...genreSpace, 0) + 1); // TMDB has ~19 common movie genres
  const g = new Array(G).fill(0);
  for (const gid of gset) if (gid < G && gid >= 0) g[gid] = 1;

  const y = Number((t as any).year || (t as any).release_date?.slice(0,4) || 2000);
  const decadeBuckets = [1970,1980,1990,2000,2010,2020];
  const d = decadeBuckets.map(D => (y>=D && y < D+10) ? 1 : 0);

  const runtime = Math.min(200, Math.max(70, Number((t as any).runtime || 110)));
  const pace = [(runtime-110)/90]; // ~[-0.44..1]; shorter=“faster”

  const pop = Math.min(1, Math.max(0, Number(t.popularity || 0)/100));
  const votes = Math.min(1, Math.max(0, Number((t as any).vote_count || 0)/20000));
  const mainstream = [0.7*pop + 0.3*votes];

  return [...g, ...d, ...pace, ...mainstream];
}

3) Smarter A/B pairs (uncertainty + distance)

Replace your A/B “pick next pair” to choose anchors the model is least sure about and furthest apart (max info).

// client/src/lib/abNext.ts
import { phi } from "./phi";
import { dot } from "./taste";
import type { Title } from "../hooks/useEnhancedCatalogue";

// picks best pair from a candidate anchor set
export function pickInformativePair(anchors: Title[], w: number[], usedIds = new Set<number>()) {
  // Precompute embeddings
  const PHI = anchors.map(t => ({ t, v: phi(t) })).filter(x => !usedIds.has(x.t.id));
  if (PHI.length < 2) throw new Error("Need >=2 anchors");
  let best = null as null | { a: Title, b: Title, score: number };

  // sample a subset for speed (anchors are ~120-160)
  const C = Math.min(110, PHI.length);
  const pool = PHI.slice(0, C);

  for (let i = 0; i < pool.length; i++) {
    for (let j = i+1; j < Math.min(pool.length, i+26); j++) { // bounded inner loop
      const A = pool[i], B = pool[j];
      const diff = A.v.map((x,k)=> x - (B.v[k] || 0));
      const margin = dot(w, diff);           // confidence for A>B (sign matters)
      const conf = Math.abs(margin);          // smaller = more uncertain
      // feature distance encourages informative contrast
      let dist = 0; for (let k=0;k<diff.length;k++) dist += Math.abs(diff[k]);
      const info = (1 - Math.min(1, conf)) * (0.5 + 0.5 * Math.min(1, dist)); // 0..1
      const score = info;
      if (!best || score > best.score) best = { a: A.t, b: B.t, score };
    }
  }
  return best!;
}


Wire it into your A/B component:

Keep your 12 rounds.

Keep your famous anchor list for A/B (not the full catalogue).

Maintain a w vector (init = zeros). After each choice: w = updateBTL(w, phi(win), phi(lose)).

For the next round: call pickInformativePair(anchors, w, usedIds).

4) Final 5 diversity re-ranker (MMR)

Take your top ~150 scored candidates (embed-aware, no repeats), then run MMR so the 5 aren’t near-duplicates.

// client/src/lib/mmr.ts
import type { Title } from "../hooks/useEnhancedCatalogue";
import { phi } from "./phi";

export function mmrSelect(titles: Title[], relScore: (t:Title)=>number, k=5, lambda=0.75) {
  const selected: Title[] = [];
  const vecs = new Map<number, number[]>();

  function sim(a: Title, b: Title) {
    const va = vecs.get(a.id) || phi(a); vecs.set(a.id, va);
    const vb = vecs.get(b.id) || phi(b); vecs.set(b.id, vb);
    // cosine
    let dot=0, na=0, nb=0;
    for (let i=0;i<va.length;i++){ dot+=va[i]*vb[i]; na+=va[i]*va[i]; nb+=vb[i]*vb[i]; }
    const la = Math.sqrt(na)||1, lb=Math.sqrt(nb)||1;
    return dot/(la*lb);
  }

  const pool = titles.slice();
  while (selected.length < k && pool.length) {
    let best = null as Title | null; let bestVal = -1e9;
    for (const t of pool) {
      const rel = relScore(t);
      const div = selected.length ? Math.max(...selected.map(s=> sim(t, s))) : 0;
      const val = lambda * rel - (1 - lambda) * div;
      if (val > bestVal) { bestVal = val; best = t; }
    }
    const idx = pool.indexOf(best!);
    if (idx >= 0) pool.splice(idx,1);
    if (best) selected.push(best);
  }
  return selected;
}


Use this right after your embed check and scoring (keep your brand/source caps).

How it behaves (and why it feels better)

Round-by-round: the next poster pair is chosen where your model is unsure and the films are meaningfully different—so every tap adds real signal.

By round 12: the taste vector is crisp (BTL online updates), so scoring isn’t “vague cosine”; it’s “what this user actually chose over that.”

Final 5: all high-match, but not 5 Batman variants—MMR ensures variety while keeping relevance.

Do you need a bigger catalogue?

Not to fix the vagueness. Vagueness is a learning & selection issue. That said, coverage helps—make sure each major lane has depth (e.g., modern horror, non-US dramas, animated beyond Pixar). Add a few more quality lists later; keep the trailer+watch links requirement.

Small UI win (optional but nice)

Show a tiny explainer under the trailer:

“Because you preferred Mad Max over Groundhog Day and picked newer thrillers.”

That transparency boosts trust.

Sources behind the approach

Netflix personalization & bandits (why interactive learning beats static A/B). 
reforge.com
geteppo.com
Scale Events

Pairwise learning (Bradley-Terry/Luce) for choices. 
Stanford University
ACER

Dueling bandits: pick comparisons that maximize information. 
Dueling Bandit Toolkit

Diversity re-ranking (MMR) so results are relevant and non-redundant. 
CMU School of Computer Science
ANU CECS Users

If you paste these blocks and keep your existing embed-aware + brand caps + “Where to watch”, the next run should feel sharper immediately.